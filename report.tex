\documentclass{article}

\usepackage{enumerate}
\usepackage[bottom=1in,top=1in]{geometry}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[pdftex,colorlinks,urlcolor=blue]{hyperref}

\geometry{letterpaper}

\begin{document}

\title{CS376 PA3 Report}

\author{
  Jiawei Yao\\
  \texttt{jwyao@stanford.edu}
  \and
  Wei Wei\\
  \texttt{wwei2@stanford.edu}
}

\maketitle

\section{Task 1 - Cosine Similarity}

Parameters and NDCG of train and dev datasets:

\begin{table}[!htb]
    \centering
    \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    \textbf{Param} & $c_{anchor}$ & $c_{body}$ & $c_{header}$ & $c_{title}$ & $c_{url}$ \\
    \hline
    \textbf{Value} & 1.00 & 3.19 & 4.40 & 4.35 & 4.30 \\
    \hline
    $\mathbf{NDCG_{train}}$ & \multicolumn{5}{c|}{0.8651} \\
    \hline
    $\mathbf{NDCG_{dev}}$ & \multicolumn{5}{c|}{0.8508} \\
    \hline
    \end{tabular}
    \caption{Parameters for Task 1}
\end{table}

\textbf{Tuning Strategy} Initially we randomly select value from $[0,5]$ for each parameter and compute NDCG train and dev set respectively\footnote{See \texttt{RandomTuner.java}.}. After normalizing the values by $c_{anchor}$, We found that with $c_{anchor}= 1.00, c_{body}\approx 1.60, c_{head}\approx 3.60, c_{title}\approx4.30, c_{url}\approx4.60$, NDCG $> 0.8670$ can be achieved on train set. On the other hand, with $c_{anchor}= 1.00, c_{body}\approx 3.40, c_{head}\approx 3.60, c_{title}\approx4.80, c_{url}\approx4.60$, NDCG $> 0.8515$ can be achieve on dev set. Then we narrow down the range for each parameter and manually tuned the paramters to get satisfactory NDCG on both sets. The final parameter value and result is in the table above.

\textbf{Reasonings behind the Weights} First, the weights for header, title and url fields are larger than that of body. This aligns with intuition because header and title contains summary information of the document. When a query term appearing in header or title, it is highly likely that the document is relevant to the query. The reasoning for url is similar. This is the same reason why human readable url is good for SEO. Second, it might be strange that anchor weight is the lowest at a first look. This is actually the result of multiplying by the anchor count -- raw term frequency is anchor field tends to be larger than term frequency in other fields.

We made the following design choices in cosine scorer:

\begin{itemize}
    \item We use body\_length + 500 to do length normalization. The actual value of added length doesn't seem to matter so much so we stick to 500 as suggested.
    \item Sublinear scaling is \emph{NOT} used on raw document term frequencies as it turns out with sublinear scaling the performance degrades.
\end{itemize}

\section{Task 2 - BM25F}

\begin{table}[!htb]
  \centering
  \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    \textbf{Param} & $B_{anchor}$ & $B_{body}$ & $B_{header}$ & $B_{title}$ & $B_{url}$ \\
    \hline
    \textbf{Value} & 0.20 & 1.00 & 0.50 & 0.90 & 1.00 \\
    \hline
    \textbf{Param} & $W_{anchor}$ & $W_{body}$ & $W_{header}$ & $W_{title}$ & $W_{url}$ \\
    \hline
    \textbf{Value} & 1.60 & 0.10 & 1.60 & 3.10 & 3.00 \\
    \hline
    \textbf{Param} & $K_1$ & $\lambda$ & $\lambda'$ & \multicolumn{2}{c|}{} \\
    \hline
    \textbf{Value} & 1.00 & 3.19 & 4.40 & \multicolumn{2}{c|}{}\\
    \hline
    $\mathbf{NDCG_{train}}$ & \multicolumn{5}{c|}{0.8919} \\
    \hline
    $\mathbf{NDCG_{dev}}$ & \multicolumn{5}{c|}{0.8829} \\
    \hline
  \end{tabular}
  \caption{Parameters for Task 2}
\end{table}

\textbf{Tuning Strategy} We use local hill climbing with random restart to tune the parameter. To achieve good performance on both training data set and dev data set, we manually adjust the parameter we get from local hill climbing tuning algorithm.

In Hill Climbing algorithm, we define the neighbors of a candidate to be as follows:
\begin{itemize}
  \item First select a parameter type to tune. Get the range of that parameter.
  \item Then generate candidates with other parameters unchanged, only changes that parameter's value.
\end{itemize}

\textbf{Reasonings behind the Weights}:

\begin{itemize}
  \item \textbf{url:} $W_{url}$ is $3.0$ which is the second largest (only a little smaller than $W_{title}$). Url has large weights makes sense becuase url often contains crucial information about this page. In fact, when I evaluated the query relevance myself, I found that url is very can tell us a lot about what this page is about. $Bf_{url}$ is $1.0$. It also makes sense because for these two urls \url{http://nlp.stanford.edu/manning/tex/} and \url{http://nlp.stanford.edu/manning/tex/avm.sty} and the query is \textit{christopher manning latex macros}, the former urls is shorter than the latter while the former contains all the key word of the latter. The latter may be more specific and contains less information of our information need.
  \item \textbf{title:} $W_{title}$ is $3.1$ which is the largest. Title has the largest weight is reasonable becuase title summarizes the contents of a web document. $Bf_{title}$ is $0.9$. It is reasonable because longer title may contain more specific information about a specific event. For example, our query is \textit{ wilbur dining}, there are a page whose title is \textit{when logging into webmail a no authentication error message displays stanford answers} and another page whose title is \textit{http://answers.stanford.edu/category/email-and-calendar/webmail}. The latter provides a better answer for user's information need because the former contains authentication error which the user didn't want to know.
  \item \textbf{body:} $W_{body}$ is only $0.1$ which is the lowest. Body is very long and may cover a lot of words in the query. The weight is low because term frequency in body is very high and we don't want body to be the most important factor in scoring documents. $Bf_{body}$ is $1.0$ and it is reasonable because if one document has long body length but has the same body hits as a shorter document, the shorter document tends to be more relevant than the longer document.
  \item \textbf{header:} $W_{header}$ is $1.6$ which has the same weight as anchor but much smaller than title and url. Header often suggests the content overview of a paragraph. Some paragraph may not be related to user's information need so the total weight given to header is not that high as title and url. $Bf_header$ is $0.5$.
  \item \textbf{anchor:} $W_{anchor}$ is $1.6$. Anchor text tells us a lot but anchor count is often very large and the anchor in other website may not summarizes the core idea of the web document so the weight is not that high as title and url but it is much more important than body. $Bf_{anchor}$ is 0.2 which suggests that the length of the anchor text is not very important to the query relevance. The length of anchor text varies a lot: some anchor has a very large count so that the lenght of anchor text is very long. We don't want these to affect the scoring of our BM25F scorer so the value is only 0.2.
\end{itemize}


\section{Task 3 - Smallest Window}

Parameters and NDCG of train and dev datasets:

\begin{table}[!htb]
    \centering
    \begin{tabular}{ | l | l | l | l | l | l | l |}
    \hline
    \textbf{Param} & $B$ & $c_{anchor}$ & $c_{body}$ & $c_{header}$ & $c_{title}$ & $c_{url}$ \\
    \hline
    \textbf{Value} & 2.65 & 1.00 & 3.19 & 4.40 & 4.35 & 4.30 \\
    \hline
    $\mathbf{NDCG_{train}}$ & \multicolumn{6}{c|}{0.8675} \\
    \hline
    $\mathbf{NDCG_{dev}}$ & \multicolumn{6}{c|}{0.8521} \\
    \hline
    \end{tabular}
    \caption{Parameters for Task 3}
\end{table}

\textbf{Tuning Strategy}

\section{Q\&A}

\paragraph{Question 1}
What was the reasoning behind giving the weights to the url, title, body, header and anchor fields for the three tasks? Were there any particular properties about the documents that allowed a higher weight to be given to one field as opposed to another?

\paragraph{Question 2}
What other metrics, not used in this assignment, could be used to get a better scoring function from the document? The metrics could either be static (query-independent, e.g. document length) or dynamic (query-dependent, e.g. smallest window).

\paragraph{Solution 2}
Static metrics such as time of creation may help to achieve a better scoring function from the document. Sometimes we may type in a time in the query string to find an article, time of creation may help a lot if we include time in the metric.

Dynamic metrics like user interests, author, location may help too. User interests is a very import feature. If I type in Jordan, and I search AI a lot, the search engine should return Jordan in UC Berkeley. Author may also be helpful because if we want to find Andrew Ng's paper, including author in the metric may help us find better result. Location is becoming more and more important. If I type in restaurant, it is better to return restaurant near your location.

\paragraph{Question 3}
In BM25F, in addition to the weights given to the fields, there are 8 other parameters, $B_{url}$, $B_{title}$, $B_{header}$, $B_{body}$, $B_{anchor}$, $\lambda$, $\lambda'$ and $K_1$. How do these parameters affect the ranking function?

\paragraph{Solution 3}

\paragraph{Question 4}
In BM25F, why did you select a particular $V_j$ function?

\paragraph{Solution 4}

\paragraph{Question 5}
For a function that includes the smallest window as one component, how does varying $B$ and the boost function change the performance of the ranking algorithm?

\paragraph{Solution 5}


\section{Extra Credit}

\end{document}
